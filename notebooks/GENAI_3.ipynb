{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate sentencepiece sacrebleu pandas"
      ],
      "metadata": {
        "id": "evKQeI1LvOV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ef0f81-094d-466c-f919-830104190b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZDPgfH9HS42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02de2d5-fc87-43ef-fb52-3eeeeffd5629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔎 Total jobs to run: 88\n",
            "→ Starting: task01_code_summarization | zero_shot @ ChatGPT\n",
            "→ Starting: task01_code_summarization | zero_shot @ Codestral\n",
            "→ Starting: task01_code_summarization | few_shot @ ChatGPT\n",
            "→ Starting: task01_code_summarization | few_shot @ Codestral\n",
            "✓ Completed: task01_code_summarization | few_shot @ ChatGPT\n",
            "→ Starting: task02_bug_fixing_off_by_one | few_shot @ ChatGPT\n",
            "✓ Completed: task01_code_summarization | zero_shot @ ChatGPT\n",
            "→ Starting: task02_bug_fixing_off_by_one | few_shot @ Codestral\n",
            "✓ Completed: task01_code_summarization | few_shot @ Codestral\n",
            "→ Starting: task02_bug_fixing_off_by_one | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task02_bug_fixing_off_by_one | few_shot @ ChatGPT\n",
            "→ Starting: task02_bug_fixing_off_by_one | chain_of_thought @ Codestral\n",
            "✓ Completed: task01_code_summarization | zero_shot @ Codestral\n",
            "→ Starting: task03_bug_classification_cpp | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task02_bug_fixing_off_by_one | few_shot @ Codestral\n",
            "→ Starting: task03_bug_classification_cpp | chain_of_thought @ Codestral\n",
            "✓ Completed: task02_bug_fixing_off_by_one | chain_of_thought @ ChatGPT\n",
            "→ Starting: task03_bug_classification_cpp | prompt_chaining @ ChatGPT\n",
            "✓ Completed: task02_bug_fixing_off_by_one | chain_of_thought @ Codestral\n",
            "→ Starting: task03_bug_classification_cpp | prompt_chaining @ Codestral\n",
            "✓ Completed: task03_bug_classification_cpp | chain_of_thought @ ChatGPT\n",
            "→ Starting: task04_email_validator | prompt_chaining @ ChatGPT\n",
            "✓ Completed: task03_bug_classification_cpp | prompt_chaining @ ChatGPT\n",
            "→ Starting: task04_email_validator | prompt_chaining @ Codestral\n",
            "✓ Completed: task04_email_validator | prompt_chaining @ ChatGPT\n",
            "→ Starting: task04_email_validator | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task03_bug_classification_cpp | chain_of_thought @ Codestral\n",
            "→ Starting: task04_email_validator | chain_of_thought @ Codestral\n",
            "✓ Completed: task03_bug_classification_cpp | prompt_chaining @ Codestral\n",
            "→ Starting: task05_flask_api | zero_shot @ ChatGPT\n",
            "✓ Completed: task04_email_validator | prompt_chaining @ Codestral\n",
            "→ Starting: task05_flask_api | zero_shot @ Codestral\n",
            "✓ Completed: task04_email_validator | chain_of_thought @ ChatGPT\n",
            "→ Starting: task05_flask_api | self_consistency @ ChatGPT\n",
            "  • SC run 1/3 for model 'gpt-4o-mini'...\n",
            "✓ Completed: task04_email_validator | chain_of_thought @ Codestral\n",
            "→ Starting: task05_flask_api | self_consistency @ Codestral\n",
            "  • SC run 1/3 for model 'Codestral-2501'...\n",
            "✓ Completed: task05_flask_api | zero_shot @ ChatGPT\n",
            "→ Starting: task06_sql_schema | zero_shot @ ChatGPT\n",
            "✓ Completed: task05_flask_api | zero_shot @ Codestral\n",
            "→ Starting: task06_sql_schema | zero_shot @ Codestral\n",
            "  • SC run 2/3 for model 'gpt-4o-mini'...\n",
            "  • SC run 2/3 for model 'Codestral-2501'...\n",
            "✓ Completed: task06_sql_schema | zero_shot @ Codestral\n",
            "→ Starting: task06_sql_schema | self_consistency @ ChatGPT\n",
            "  • SC run 1/3 for model 'gpt-4o-mini'...\n",
            "  • SC run 3/3 for model 'Codestral-2501'...\n",
            "✓ Completed: task06_sql_schema | zero_shot @ ChatGPT\n",
            "→ Starting: task06_sql_schema | self_consistency @ Codestral\n",
            "  • SC run 1/3 for model 'Codestral-2501'...\n",
            "  • SC run 3/3 for model 'gpt-4o-mini'...\n",
            "✓ Completed: task05_flask_api | self_consistency @ ChatGPT\n",
            "→ Starting: task07_null_deref_java | few_shot @ ChatGPT\n",
            "✓ Completed: task05_flask_api | self_consistency @ Codestral\n",
            "→ Starting: task07_null_deref_java | few_shot @ Codestral\n",
            "✓ Completed: task07_null_deref_java | few_shot @ ChatGPT\n",
            "→ Starting: task07_null_deref_java | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task07_null_deref_java | few_shot @ Codestral\n",
            "→ Starting: task07_null_deref_java | chain_of_thought @ Codestral\n",
            "  • SC run 2/3 for model 'gpt-4o-mini'...\n",
            "✓ Completed: task07_null_deref_java | chain_of_thought @ ChatGPT\n",
            "→ Starting: task08_csv_parser | few_shot @ ChatGPT\n",
            "✓ Completed: task07_null_deref_java | chain_of_thought @ Codestral\n",
            "→ Starting: task08_csv_parser | few_shot @ Codestral\n",
            "✓ Completed: task08_csv_parser | few_shot @ ChatGPT\n",
            "→ Starting: task08_csv_parser | chain_of_thought @ ChatGPT\n",
            "  • SC run 2/3 for model 'Codestral-2501'...\n",
            "  • SC run 3/3 for model 'gpt-4o-mini'...\n",
            "✓ Completed: task08_csv_parser | few_shot @ Codestral\n",
            "→ Starting: task08_csv_parser | chain_of_thought @ Codestral\n",
            "✓ Completed: task08_csv_parser | chain_of_thought @ ChatGPT\n",
            "→ Starting: task09_kotlin_api | prompt_chaining @ ChatGPT\n",
            "  • SC run 3/3 for model 'Codestral-2501'...\n",
            "✓ Completed: task08_csv_parser | chain_of_thought @ Codestral\n",
            "→ Starting: task09_kotlin_api | prompt_chaining @ Codestral\n",
            "✓ Completed: task06_sql_schema | self_consistency @ ChatGPT\n",
            "→ Starting: task09_kotlin_api | self_consistency @ ChatGPT\n",
            "  • SC run 1/3 for model 'gpt-4o-mini'...\n",
            "✓ Completed: task06_sql_schema | self_consistency @ Codestral\n",
            "→ Starting: task09_kotlin_api | self_consistency @ Codestral\n",
            "  • SC run 1/3 for model 'Codestral-2501'...\n",
            "✓ Completed: task09_kotlin_api | prompt_chaining @ Codestral\n",
            "→ Starting: task10_func_summary_py | prompt_chaining @ ChatGPT\n",
            "✓ Completed: task10_func_summary_py | prompt_chaining @ ChatGPT\n",
            "→ Starting: task10_func_summary_py | prompt_chaining @ Codestral\n",
            "✓ Completed: task10_func_summary_py | prompt_chaining @ Codestral\n",
            "→ Starting: task10_func_summary_py | self_consistency @ ChatGPT\n",
            "  • SC run 1/3 for model 'gpt-4o-mini'...\n",
            "  • SC run 2/3 for model 'gpt-4o-mini'...\n",
            "  • SC run 2/3 for model 'gpt-4o-mini'...\n",
            "  • SC run 2/3 for model 'Codestral-2501'...\n",
            "  • SC run 3/3 for model 'gpt-4o-mini'...\n",
            "✓ Completed: task09_kotlin_api | prompt_chaining @ ChatGPT\n",
            "→ Starting: task10_func_summary_py | self_consistency @ Codestral\n",
            "  • SC run 1/3 for model 'Codestral-2501'...\n",
            "  • SC run 3/3 for model 'gpt-4o-mini'...\n",
            "  • SC run 2/3 for model 'Codestral-2501'...\n",
            "  • SC run 3/3 for model 'Codestral-2501'...\n",
            "✓ Completed: task10_func_summary_py | self_consistency @ ChatGPT\n",
            "→ Starting: task11_prompt_from_comments | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task10_func_summary_py | self_consistency @ Codestral\n",
            "→ Starting: task11_prompt_from_comments | chain_of_thought @ Codestral\n",
            "✓ Completed: task11_prompt_from_comments | chain_of_thought @ ChatGPT\n",
            "→ Starting: task11_prompt_from_comments | prompt_chaining @ ChatGPT\n",
            "✓ Completed: task11_prompt_from_comments | prompt_chaining @ ChatGPT\n",
            "→ Starting: task11_prompt_from_comments | prompt_chaining @ Codestral\n",
            "✓ Completed: task11_prompt_from_comments | chain_of_thought @ Codestral\n",
            "→ Starting: task12_optimize_loop | zero_shot @ ChatGPT\n",
            "  • SC run 3/3 for model 'Codestral-2501'...\n",
            "✓ Completed: task11_prompt_from_comments | prompt_chaining @ Codestral\n",
            "→ Starting: task12_optimize_loop | zero_shot @ Codestral\n",
            "✓ Completed: task12_optimize_loop | zero_shot @ Codestral\n",
            "→ Starting: task12_optimize_loop | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task12_optimize_loop | zero_shot @ ChatGPT\n",
            "→ Starting: task12_optimize_loop | chain_of_thought @ Codestral\n",
            "✓ Completed: task09_kotlin_api | self_consistency @ ChatGPT\n",
            "→ Starting: task13_data_class_java | zero_shot @ ChatGPT\n",
            "✓ Completed: task09_kotlin_api | self_consistency @ Codestral\n",
            "→ Starting: task13_data_class_java | zero_shot @ Codestral\n",
            "✓ Completed: task12_optimize_loop | chain_of_thought @ ChatGPT\n",
            "→ Starting: task13_data_class_java | few_shot @ ChatGPT\n",
            "✓ Completed: task12_optimize_loop | chain_of_thought @ Codestral\n",
            "→ Starting: task13_data_class_java | few_shot @ Codestral\n",
            "✓ Completed: task13_data_class_java | few_shot @ ChatGPT\n",
            "→ Starting: task14_unit_test_py | zero_shot @ ChatGPT\n",
            "✓ Completed: task13_data_class_java | zero_shot @ ChatGPT\n",
            "→ Starting: task14_unit_test_py | zero_shot @ Codestral\n",
            "✓ Completed: task13_data_class_java | zero_shot @ Codestral\n",
            "→ Starting: task14_unit_test_py | few_shot @ ChatGPT\n",
            "✓ Completed: task13_data_class_java | few_shot @ Codestral\n",
            "→ Starting: task14_unit_test_py | few_shot @ Codestral\n",
            "✓ Completed: task14_unit_test_py | few_shot @ ChatGPT\n",
            "→ Starting: task15_refactor_nested_if | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task14_unit_test_py | few_shot @ Codestral\n",
            "→ Starting: task15_refactor_nested_if | chain_of_thought @ Codestral\n",
            "✓ Completed: task14_unit_test_py | zero_shot @ Codestral\n",
            "→ Starting: task15_refactor_nested_if | zero_shot @ ChatGPT\n",
            "✓ Completed: task14_unit_test_py | zero_shot @ ChatGPT\n",
            "→ Starting: task15_refactor_nested_if | zero_shot @ Codestral\n",
            "✓ Completed: task15_refactor_nested_if | zero_shot @ ChatGPT\n",
            "→ Starting: task16_detect_infinite_loop | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task15_refactor_nested_if | zero_shot @ Codestral\n",
            "→ Starting: task16_detect_infinite_loop | chain_of_thought @ Codestral\n",
            "✓ Completed: task15_refactor_nested_if | chain_of_thought @ Codestral\n",
            "→ Starting: task16_detect_infinite_loop | prompt_chaining @ ChatGPT\n",
            "✓ Completed: task16_detect_infinite_loop | chain_of_thought @ Codestral\n",
            "→ Starting: task16_detect_infinite_loop | prompt_chaining @ Codestral\n",
            "✓ Completed: task16_detect_infinite_loop | prompt_chaining @ ChatGPT\n",
            "→ Starting: task17_javadoc_summary | zero_shot @ ChatGPT\n",
            "✓ Completed: task17_javadoc_summary | zero_shot @ ChatGPT\n",
            "→ Starting: task17_javadoc_summary | zero_shot @ Codestral\n",
            "✓ Completed: task15_refactor_nested_if | chain_of_thought @ ChatGPT\n",
            "→ Starting: task17_javadoc_summary | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task16_detect_infinite_loop | prompt_chaining @ Codestral\n",
            "→ Starting: task17_javadoc_summary | chain_of_thought @ Codestral\n",
            "✓ Completed: task17_javadoc_summary | zero_shot @ Codestral\n",
            "→ Starting: task18_comment_generator | prompt_chaining @ ChatGPT\n",
            "✓ Completed: task17_javadoc_summary | chain_of_thought @ ChatGPT\n",
            "→ Starting: task18_comment_generator | prompt_chaining @ Codestral\n",
            "✓ Completed: task16_detect_infinite_loop | chain_of_thought @ ChatGPT\n",
            "→ Starting: task18_comment_generator | zero_shot @ ChatGPT\n",
            "✓ Completed: task18_comment_generator | prompt_chaining @ ChatGPT\n",
            "→ Starting: task18_comment_generator | zero_shot @ Codestral\n",
            "✓ Completed: task18_comment_generator | prompt_chaining @ Codestral\n",
            "→ Starting: task19_code_translation_py2java | zero_shot @ ChatGPT\n",
            "✓ Completed: task18_comment_generator | zero_shot @ Codestral\n",
            "→ Starting: task19_code_translation_py2java | zero_shot @ Codestral\n",
            "✓ Completed: task18_comment_generator | zero_shot @ ChatGPT\n",
            "→ Starting: task19_code_translation_py2java | prompt_chaining @ ChatGPT\n",
            "✓ Completed: task19_code_translation_py2java | zero_shot @ ChatGPT\n",
            "→ Starting: task19_code_translation_py2java | prompt_chaining @ Codestral\n",
            "✓ Completed: task19_code_translation_py2java | zero_shot @ Codestral\n",
            "→ Starting: task20_sorting_explanation | few_shot @ ChatGPT\n",
            "✓ Completed: task19_code_translation_py2java | prompt_chaining @ ChatGPT\n",
            "→ Starting: task20_sorting_explanation | few_shot @ Codestral\n",
            "✓ Completed: task17_javadoc_summary | chain_of_thought @ Codestral\n",
            "→ Starting: task20_sorting_explanation | zero_shot @ ChatGPT\n",
            "✓ Completed: task19_code_translation_py2java | prompt_chaining @ Codestral\n",
            "→ Starting: task20_sorting_explanation | zero_shot @ Codestral\n",
            "✓ Completed: task20_sorting_explanation | few_shot @ ChatGPT\n",
            "→ Starting: task21_missing_docstring | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task20_sorting_explanation | zero_shot @ ChatGPT\n",
            "→ Starting: task21_missing_docstring | chain_of_thought @ Codestral\n",
            "✓ Completed: task20_sorting_explanation | few_shot @ Codestral\n",
            "→ Starting: task21_missing_docstring | zero_shot @ ChatGPT\n",
            "✓ Completed: task20_sorting_explanation | zero_shot @ Codestral\n",
            "→ Starting: task21_missing_docstring | zero_shot @ Codestral\n",
            "✓ Completed: task21_missing_docstring | zero_shot @ ChatGPT\n",
            "→ Starting: task22_variable_renaming | few_shot @ ChatGPT\n",
            "✓ Completed: task21_missing_docstring | zero_shot @ Codestral\n",
            "→ Starting: task22_variable_renaming | few_shot @ Codestral\n",
            "✓ Completed: task22_variable_renaming | few_shot @ ChatGPT\n",
            "→ Starting: task22_variable_renaming | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task21_missing_docstring | chain_of_thought @ Codestral\n",
            "→ Starting: task22_variable_renaming | chain_of_thought @ Codestral\n",
            "✓ Completed: task21_missing_docstring | chain_of_thought @ ChatGPT\n",
            "✓ Completed: task22_variable_renaming | few_shot @ Codestral\n",
            "✓ Completed: task22_variable_renaming | chain_of_thought @ Codestral\n",
            "✓ Completed: task22_variable_renaming | chain_of_thought @ ChatGPT\n",
            "✅ All outputs have been generated and saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import evaluate\n",
        "\n",
        "# Set environment variable for API key (example, remove in production)\n",
        "# Create your PAT token by following instructions here:\n",
        "# https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
        "# grab the token from the token.txt file\n",
        "with open(\"token.txt\", \"r\") as f:\n",
        "  GITHUB_TOKEN = f.read().strip()\n",
        "\n",
        "\n",
        "# Initialize the OpenAI client (replace base_url if needed)\n",
        "client = OpenAI(\n",
        "    base_url=\"https://models.inference.ai.azure.com\",\n",
        "    api_key=os.getenv('GITHUB_TOKEN') or os.getenv('OPENAI_API_KEY')\n",
        ")\n",
        "\n",
        "# Define models\n",
        "MODEL_CONFIG = [\n",
        "    (\"gpt-4o-mini\", \"ChatGPT\"),\n",
        "    (\"Codestral-2501\", \"Codestral\"),\n",
        "]\n",
        "\n",
        "model_choices, model_names = zip(*MODEL_CONFIG)\n",
        "\n",
        "# Updated EXAMPLES dictionary with all 22 tasks in chronological order\n",
        "EXAMPLES = {\n",
        "    \"task01_code_summarization\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"public Map<String, Integer> countWordFrequency(List<String> words) {\n",
        "    Map<String, Integer> freqMap = new HashMap<>();\n",
        "    for (String word : words) {\n",
        "        freqMap.put(word, freqMap.getOrDefault(word, 0) + 1);\n",
        "    }\n",
        "    return freqMap;\n",
        "}\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Summarize the functionality of the following Java method:\",\n",
        "            \"few_shot\": \"Example:\\nInput: a Java method that counts the frequency of each character in a string.\\nOutput: This method takes a string as input and returns a map where each key is a character from the string, and the value is the number of times that character appears.\\n\\nNow, summarize the functionality of the following Java method:\"\n",
        "        }\n",
        "    },\n",
        "    \"task02_bug_fixing_off_by_one\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def sum_range(start, end):\n",
        "    total = 0\n",
        "    for i in range(start, end):\n",
        "        total += i\n",
        "    return total\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"few_shot\": \"Example:\\nInput: start=1, end=4 → Output: 6 (This sums 1+2+3)\\nNow identify and fix the off-by-one error in the following function:\",\n",
        "            \"chain_of_thought\": \"Think step-by-step to find and correct the off-by-one error in the following Python function:\"\n",
        "        }\n",
        "    },\n",
        "    \"task03_bug_classification_cpp\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"int * getArray(int size) {\n",
        "    int arr[size]; // Warning: local array\n",
        "    return arr;    // Bug: returning pointer to local variable\n",
        "}\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"chain_of_thought\": \"Walk through your reasoning step-by-step and classify the bug in the following C++ function:\",\n",
        "            \"prompt_chaining\": \"Step 1: Identify the bug in the following C++ function.\\nStep 2: Explain why it occurs and its consequences.\"\n",
        "        }\n",
        "    },\n",
        "    \"task04_email_validator\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def is_valid_email(email):\n",
        "    # TODO: Complete using regex\n",
        "    pass\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"prompt_chaining\": \"Step 1: Provide a regex pattern for basic email addresses (e.g., user@domain.com).\\nStep 2: Implement `is_valid_email` using that pattern in the following code:\",\n",
        "            \"chain_of_thought\": \"Think step-by-step to derive a regex and implement `is_valid_email` in the following code:\"\n",
        "        }\n",
        "    },\n",
        "    \"task05_flask_api\": {\n",
        "        \"type\": \"generation\",\n",
        "        \"expected\": \"\"\"from flask import Flask, jsonify\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/greet/<username>')\n",
        "def greet(username):\n",
        "    return jsonify({'greeting': f'Hello, {username}!'})\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Create a Flask `/greet/<username>` endpoint that returns a JSON greeting.\",\n",
        "            \"self_consistency\": \"Create a Flask `/greet/<username>` endpoint that returns a JSON greeting.\"\n",
        "        }\n",
        "    },\n",
        "    \"task06_sql_schema\": {\n",
        "        \"type\": \"generation\",\n",
        "        \"expected\": \"\"\"-- users(id INT PRIMARY KEY, name VARCHAR(100));\n",
        "-- books(id INT PRIMARY KEY, title VARCHAR(200));\n",
        "-- reviews(id INT PRIMARY KEY, user_id INT REFERENCES users(id), book_id INT REFERENCES books(id), rating INT);\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Write SQL schema (tables, primary & foreign keys) for a review app with users, books, and reviews.\",\n",
        "            \"self_consistency\": \"Write the SQL schema for a review app.\"\n",
        "        }\n",
        "    },\n",
        "    \"task07_null_deref_java\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"public int getLength(String s) {\n",
        "    return s.length(); // What if s is null?\n",
        "}\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"few_shot\": \"Example:\\nInput: a method with a null check before length().\\nOutput: Checks if the string is null before calling length to avoid null-dereference.\\nNow identify null-dereference risk in the following code:\",\n",
        "            \"chain_of_thought\": \"Reason step-by-step to find any null-dereference risk in the following Java code:\"\n",
        "        }\n",
        "    },\n",
        "    \"task08_csv_parser\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def parse_csv_line(line):\n",
        "    return line.split(',')  # Incomplete: doesn't handle quoted fields\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"few_shot\": \"Example:\\nInput: '\\\"a,b\\\",c' → Output: ['a,b','c']\\nNow improve the following CSV parser:\",\n",
        "            \"chain_of_thought\": \"Think step-by-step to split CSV fields correctly, handling quotes, in the following code:\"\n",
        "        }\n",
        "    },\n",
        "    \"task09_kotlin_api\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"data class Product(val id: Int, val name: String, val price: Double)\n",
        "// TODO: Create GET and POST endpoints using Ktor\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"prompt_chaining\": \"Step 1: Define GET `/product/{id}` returning JSON.\\nStep 2: Define POST endpoint accepting a Product in the body for the following code:\",\n",
        "            \"self_consistency\": \"Convert the following Kotlin data class to a REST API with GET and POST endpoints using Ktor.\"\n",
        "        }\n",
        "    },\n",
        "    \"task10_func_summary_py\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def reverse_words(sentence):\n",
        "    return ' '.join(sentence.split()[::-1])\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"prompt_chaining\": \"Step 1: Describe what the following function does.\\nStep 2: Summarize it in one sentence:\",\n",
        "            \"self_consistency\": \"Write a brief summary of the following function.\"\n",
        "        }\n",
        "    },\n",
        "    \"task11_prompt_from_comments\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"# This function checks if a number is prime\n",
        "def is_prime(n):\n",
        "    if n <= 1: return False\n",
        "    for i in range(2, int(n**0.5)+1):\n",
        "        if n % i == 0: return False\n",
        "    return True\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"chain_of_thought\": \"Explain step-by-step how to craft a prompt to generate the following code:\",\n",
        "            \"prompt_chaining\": \"Step 1: Write a system instruction that sets the task.\\nStep 2: Provide the comment and ask for implementation for the following code:\"\n",
        "        }\n",
        "    },\n",
        "    \"task12_optimize_loop\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"squares = []\n",
        "for i in range(1000000):\n",
        "    squares.append(i * i)\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Optimize the following Python loop for performance:\",\n",
        "            \"chain_of_thought\": \"Explain step-by-step how you would optimize the following loop:\"\n",
        "        }\n",
        "    },\n",
        "    \"task13_data_class_java\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"public class Person {\n",
        "    private String name;\n",
        "    private int age;\n",
        "    public Person(String name, int age) {\n",
        "        this.name = name;\n",
        "        this.age = age;\n",
        "    }\n",
        "    public String getName() { return name; }\n",
        "    public int getAge() { return age; }\n",
        "}\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Convert the following Java class into a Java 16+ record:\",\n",
        "            \"few_shot\": \"Example:\\nInput: public class Point { int x; int y; public Point(int x, int y) { this.x = x; this.y = y; } }\\nOutput: record Point(int x, int y) {}\\n\\nNow convert the following class:\"\n",
        "        }\n",
        "    },\n",
        "    \"task14_unit_test_py\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def is_even(n):\n",
        "    return n % 2 == 0\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Write unit tests using `unittest` for the following function:\",\n",
        "            \"few_shot\": \"Example:\\nFunction: def add(a, b): return a + b\\nTest: assert add(2, 3) == 5\\n\\nNow test the following function:\"\n",
        "        }\n",
        "    },\n",
        "    \"task15_refactor_nested_if\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"if user:\n",
        "    if user.is_active:\n",
        "        if user.is_admin:\n",
        "            return True\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"chain_of_thought\": \"Refactor the following nested `if` statements for clarity. Explain your reasoning:\",\n",
        "            \"zero_shot\": \"Simplify the following nested `if` statements:\"\n",
        "        }\n",
        "    },\n",
        "    \"task16_detect_infinite_loop\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"i = 0\n",
        "while i < 5:\n",
        "    print(i)\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"chain_of_thought\": \"Walk through the logic step-by-step to detect any infinite loop in the following code:\",\n",
        "            \"prompt_chaining\": \"Step 1: Simulate what the following loop does.\\nStep 2: Determine if it ever terminates:\"\n",
        "        }\n",
        "    },\n",
        "    \"task17_javadoc_summary\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"/**\n",
        " *\n",
        " */\n",
        "public int factorial(int n) {\n",
        "    if (n <= 1) return 1;\n",
        "    return n * factorial(n - 1);\n",
        "}\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Generate a Javadoc summary for the following method:\",\n",
        "            \"chain_of_thought\": \"First describe what the following method does, then generate a Javadoc summary:\"\n",
        "        }\n",
        "    },\n",
        "    \"task18_comment_generator\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def factorial(n):\n",
        "    if n == 0:\n",
        "        return 1\n",
        "    return n * factorial(n-1)\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"prompt_chaining\": \"Step 1: Identify the purpose of each line.\\nStep 2: Add comments to the following code:\",\n",
        "            \"zero_shot\": \"Add comments to the following recursive factorial function:\"\n",
        "        }\n",
        "    },\n",
        "    \"task19_code_translation_py2java\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def square(n):\n",
        "    return n * n\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Translate the following Python function to Java:\",\n",
        "            \"prompt_chaining\": \"Step 1: Describe what the following function does.\\nStep 2: Translate it into Java:\"\n",
        "        }\n",
        "    },\n",
        "    \"task20_sorting_explanation\": {\n",
        "        \"type\": \"generation\",\n",
        "        \"expected\": \"Merge sort divides the array into halves, recursively sorts them, and merges the results.\",\n",
        "        \"strategies\": {\n",
        "            \"few_shot\": \"Example:\\nInput: Bubble Sort\\nOutput: Bubble sort repeatedly compares and swaps adjacent elements.\\n\\nNow explain Merge Sort:\",\n",
        "            \"zero_shot\": \"Explain how merge sort works in simple terms:\"\n",
        "        }\n",
        "    },\n",
        "    \"task21_missing_docstring\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def add(a, b):\n",
        "    return a + b\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"chain_of_thought\": \"Describe what the following function does step-by-step, then write a docstring:\",\n",
        "            \"zero_shot\": \"Write a docstring for the following function:\"\n",
        "        }\n",
        "    },\n",
        "    \"task22_variable_renaming\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"a = 5\n",
        "b = 10\n",
        "print(a + b)\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"few_shot\": \"Example:\\nInput: a=5, b=10, return a+b\\nOutput: num1=5, num2=10, return num1+num2\\n\\nNow rename variables to be more descriptive in the following code:\",\n",
        "            \"chain_of_thought\": \"Reason step-by-step to rename variables for clarity in the following code:\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# Helper to build the prompt based on task type\n",
        "def build_prompt(prefix, snippet=None):\n",
        "    if snippet:\n",
        "        lang = 'java' if 'java' in snippet else 'python' if 'def' in snippet else 'cpp'\n",
        "        return f\"{prefix}\\n```{lang}\\n{snippet}\\n```\"\n",
        "    return prefix\n",
        "\n",
        "# Safe chat completion with retry\n",
        "def safe_chat_completion(model, prompt, max_retries=3):\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=1024,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return resp.choices[0].message.content.strip()\n",
        "        except Exception as e:\n",
        "            msg = str(e)\n",
        "            m = re.search(r\"wait (\\d+) seconds\", msg)\n",
        "            if m:\n",
        "                wait_secs = int(m.group(1)) + 1\n",
        "                print(f\"🔒 Rate-limit on '{model}', sleeping {wait_secs}s then retry (attempt {attempt})...\")\n",
        "                time.sleep(wait_secs)\n",
        "                continue\n",
        "            backoff = 2 ** attempt\n",
        "            print(f\"⚠️  Error on attempt {attempt} for '{model}': {e}\")\n",
        "            print(f\"  → backing off {backoff}s before retry.\")\n",
        "            time.sleep(backoff)\n",
        "    print(f\"❌ All retries failed for model '{model}'.\")\n",
        "    return None\n",
        "\n",
        "# Self-consistency runner using BLEU-4 similarity among outputs\n",
        "def run_self_consistency(model, prompt, runs=3):\n",
        "    outputs = []\n",
        "    for i in range(1, runs + 1):\n",
        "        print(f\"  • SC run {i}/{runs} for model '{model}'...\")\n",
        "        out = safe_chat_completion(model, prompt)\n",
        "        if out:\n",
        "            outputs.append(out)\n",
        "    if not outputs:\n",
        "        return None, []\n",
        "    if len(outputs) == 1:\n",
        "        return outputs[0], outputs\n",
        "\n",
        "    # Load BLEU metric\n",
        "    bleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "    # Compute average BLEU-4 score of each output against others\n",
        "    avg_scores = []\n",
        "    for i, cand in enumerate(outputs):\n",
        "        score_sum = 0.0\n",
        "        count = 0\n",
        "        for j, ref in enumerate(outputs):\n",
        "            if i == j:\n",
        "                continue\n",
        "            result = bleu.compute(predictions=[cand], references=[[ref]])\n",
        "            score_sum += result[\"score\"]\n",
        "            count += 1\n",
        "        avg_scores.append(score_sum / count if count else 0.0)\n",
        "\n",
        "    # Select the output with the highest average BLEU score\n",
        "    best_idx = avg_scores.index(max(avg_scores))\n",
        "    return outputs[best_idx], outputs\n",
        "\n",
        "# Worker executed in parallel\n",
        "def worker(args):\n",
        "    task_key, strat_key, model_id, model_name, prompt = args\n",
        "    print(f\"→ Starting: {task_key} | {strat_key} @ {model_name}\")\n",
        "    timestamp = datetime.utcnow().isoformat()\n",
        "    if \"self_consistency\" in strat_key:\n",
        "        output, variants = run_self_consistency(model_id, prompt)\n",
        "    else:\n",
        "        output = safe_chat_completion(model_id, prompt)\n",
        "        variants = []\n",
        "    print(f\"✓ Completed: {task_key} | {strat_key} @ {model_name}\")\n",
        "    return {\n",
        "        \"task\": task_key,\n",
        "        \"strategy\": strat_key,\n",
        "        \"model\": model_name,\n",
        "        \"model_id\": model_id,\n",
        "        \"prompt\": prompt,\n",
        "        \"output\": output,\n",
        "        \"variants\": variants,\n",
        "        \"timestamp\": timestamp\n",
        "    }\n",
        "\n",
        "# Orchestrator: builds jobs, runs them, and saves outputs\n",
        "def generate_all():\n",
        "    jobs = []\n",
        "    for task_key, info in EXAMPLES.items():\n",
        "        snippet = info.get(\"snippet\") if info[\"type\"] == \"analysis\" else None\n",
        "        for strat_key, prefix in info[\"strategies\"].items():\n",
        "            prompt = build_prompt(prefix, snippet)\n",
        "            for model_id, model_name in MODEL_CONFIG:\n",
        "                jobs.append((task_key, strat_key, model_id, model_name, prompt))\n",
        "    print(f\"🔎 Total jobs to run: {len(jobs)}\")\n",
        "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        results = list(executor.map(worker, jobs))\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(\"all_prompts_and_outputs.csv\", index=False)\n",
        "    df.to_json(\"all_prompts_and_outputs.json\", orient=\"records\", indent=2)\n",
        "    print(\"✅ All outputs have been generated and saved.\")\n",
        "\n",
        "# Run the full pipeline\n",
        "if __name__ == '__main__':\n",
        "    generate_all()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PJyGxJDDd-lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rgYPxnh6c5ry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}