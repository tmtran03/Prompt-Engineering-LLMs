{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evKQeI1LvOV9",
        "outputId": "486e3133-41a5-45f8-cab6-79c4a49fa0f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, portalocker, fsspec, dill, colorama, sacrebleu, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 datasets-3.5.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.12.0 multiprocess-0.70.16 portalocker-3.1.1 sacrebleu-2.5.1 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate sentencepiece sacrebleu pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f90b64b0b4a41799726f4a280bbbf53",
            "bcf42ad972d543b6bb8a1b05416303eb",
            "f57da60c387244a8803f2ab97e7ce263",
            "2d38b2a95edf4e6e82d9a936ede02d43",
            "8c5c32b91aff4fbe96264a63ee708d38",
            "ea270adbb28e414cb8620ced981b1a55",
            "f695656ee8554f4690f2882389616d76",
            "4f45efad3c3145aaaf3098b9141fa4d1",
            "1ad62a901af948b4a6a227b0c78c3c85",
            "2236967ca8764d8bab1d6ae53adb9bb9",
            "c1c14289145244a087ee298cef3ace34",
            "679b8022a0744af5af1f1162dcf7c18b",
            "971f58f582d3426f8fb3e78dbeaf8d2e",
            "cd46b837c5ec44b297376a70f522464c",
            "34608d23b28e455a83af745444e1cdbf",
            "548f14f5e3884990a9d72807f3732b55",
            "9209616024bd44e788eba940d296f704",
            "ac3d6c51f66f467aa5cee9a8852639a5",
            "36b06ada6e574b70a2b02e7fcc8e14de",
            "cf00bb3a548c4b1783a13ae45b32c856",
            "156943ba5ed7469da9e98ef6b8b21f24",
            "2d626c92298b4d6e9f2133c60ff32540"
          ]
        },
        "id": "HZDPgfH9HS42",
        "outputId": "6f0f73f6-ad76-418b-961c-7b10b3b22728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ PROMPT:\n",
            " Summarize the functionality of the following Java method:\n",
            "```java\n",
            "public Map<String, Integer> countWordFrequency(List<String> words) {\n",
            "    Map<String, Integer> freqMap = new HashMap<>();\n",
            "    for (String word : words) {\n",
            "        freqMap.put(word, freqMap.getOrDefault(word, 0) + 1);\n",
            "    }\n",
            "    return freqMap;\n",
            "}\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Example:\n",
            "Input: a Java method that counts the frequency of each character in a string.\n",
            "Output: This method takes a string as input and returns a map where each key is a character from the string, and the value is the number of times that character appears.\n",
            "\n",
            "Now, summarize the functionality of the following Java method:\n",
            "```java\n",
            "public Map<String, Integer> countWordFrequency(List<String> words) {\n",
            "    Map<String, Integer> freqMap = new HashMap<>();\n",
            "    for (String word : words) {\n",
            "        freqMap.put(word, freqMap.getOrDefault(word, 0) + 1);\n",
            "    }\n",
            "    return freqMap;\n",
            "}\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Example:\n",
            "Input: start=1, end=4 â†’ Output: 6 (This sums 1+2+3)\n",
            "Now identify and fix the off-by-one error in the following function:\n",
            "```python\n",
            "def sum_range(start, end):\n",
            "    total = 0\n",
            "    for i in range(start, end):\n",
            "        total += i\n",
            "    return total\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Think step-by-step to find and correct the off-by-one error in the following Python function:\n",
            "```python\n",
            "def sum_range(start, end):\n",
            "    total = 0\n",
            "    for i in range(start, end):\n",
            "        total += i\n",
            "    return total\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Walk through your reasoning step-by-step and classify the bug in the following C++ function:\n",
            "```cpp\n",
            "int * getArray(int size) {\n",
            "    int arr[size]; // Warning: local array\n",
            "    return arr;    // Bug: returning pointer to local variable\n",
            "}\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Identify the bug in the following C++ function.\n",
            "Step 2: Explain why it occurs and its consequences.\n",
            "```cpp\n",
            "int * getArray(int size) {\n",
            "    int arr[size]; // Warning: local array\n",
            "    return arr;    // Bug: returning pointer to local variable\n",
            "}\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Provide a regex pattern for basic email addresses (e.g., user@domain.com).\n",
            "Step 2: Implement `is_valid_email` using that pattern in the following code:\n",
            "```python\n",
            "def is_valid_email(email):\n",
            "    # TODO: Complete using regex\n",
            "    pass\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Think step-by-step to derive a regex and implement `is_valid_email` in the following code:\n",
            "```python\n",
            "def is_valid_email(email):\n",
            "    # TODO: Complete using regex\n",
            "    pass\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Create a Flask `/greet/<username>` endpoint that returns a JSON greeting.\n",
            "```None\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Create a Flask `/greet/<username>` endpoint that returns a JSON greeting.\n",
            "```None\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Write SQL schema (tables, primary & foreign keys) for a review app with users, books, and reviews. -- TODO : Design schema with appropriate keys and constraints -- Tables : users (id , name ), books (id , title ), reviews (id , user_id , book_id , rating )\n",
            "```None\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Write SQL schema (tables, primary & foreign keys) for a review app with users, books, and reviews. -- TODO : Design schema with appropriate keys and constraints -- Tables : users (id , name ), books (id , title ), reviews (id , user_id , book_id , rating )\n",
            "```None\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Example:\n",
            "Input: a method with a null check before length().\n",
            "Output: Checks if the string is null before calling length to avoid null-dereference.\n",
            "Now identify null-dereference risk in the following code:\n",
            "```java\n",
            "public int getLength(String s) {\n",
            "    return s.length(); // What if s is null?\n",
            "}\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Reason step-by-step to find any null-dereference risk in the following Java code:\n",
            "```java\n",
            "public int getLength(String s) {\n",
            "    return s.length(); // What if s is null?\n",
            "}\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Example:\n",
            "Input: '\"a,b\",c' â†’ Output: ['a,b','c']\n",
            "Now improve the following CSV parser:\n",
            "```python\n",
            "def parse_csv_line(line):\n",
            "    return line.split(',')  # Incomplete: doesn't handle quoted fields\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Think step-by-step to split CSV fields correctly, handling quotes, in the following code:\n",
            "```python\n",
            "def parse_csv_line(line):\n",
            "    return line.split(',')  # Incomplete: doesn't handle quoted fields\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Define GET `/product/{id}` returning JSON.\n",
            "Step 2: Define POST endpoint accepting a Product in the body for the following code:\n",
            "```cpp\n",
            "data class Product(val id: Int, val name: String, val price: Double)\n",
            "// TODO: Create GET and POST endpoints using Ktor\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Convert the following Kotlin data class to a REST API with GET and POST endpoints using Ktor.\n",
            "```cpp\n",
            "data class Product(val id: Int, val name: String, val price: Double)\n",
            "// TODO: Create GET and POST endpoints using Ktor\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Describe what the following function does.\n",
            "Step 2: Summarize it in one sentence:\n",
            "```python\n",
            "def reverse_words(sentence):\n",
            "    return ' '.join(sentence.split()[::-1])\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Write a brief summary of the following function.\n",
            "```python\n",
            "def reverse_words(sentence):\n",
            "    return ' '.join(sentence.split()[::-1])\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Explain step-by-step how to craft a prompt to generate the following code:\n",
            "```python\n",
            "# This function checks if a number is prime\n",
            "def is_prime(n):\n",
            "    if n <= 1: return False\n",
            "    for i in range(2, int(n**0.5)+1):\n",
            "        if n % i == 0: return False\n",
            "    return True\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Write a system instruction that sets the task.\n",
            "Step 2: Provide the comment and ask for implementation for the following code:\n",
            "```python\n",
            "# This function checks if a number is prime\n",
            "def is_prime(n):\n",
            "    if n <= 1: return False\n",
            "    for i in range(2, int(n**0.5)+1):\n",
            "        if n % i == 0: return False\n",
            "    return True\n",
            "\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " The logic fails for n = 0 due to incorrect loop bounds. Revise it so the function returns 1 for 0 and behaves consistently for all inputs.\n",
            "```python\n",
            "def factorial(n):\n",
            "    result = 1\n",
            "    for i in range(1, n):\n",
            "        result *= i\n",
            "    return result\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step-by-step, identify how the loop behaves for n = 0 and adjust it to include the base case explicitly.\n",
            "```python\n",
            "def factorial(n):\n",
            "    result = 1\n",
            "    for i in range(1, n):\n",
            "        result *= i\n",
            "    return result\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Example:\n",
            "Input: struct Node *head; int key = 4;\n",
            "Output: Node with value 4 is removed from the list.\n",
            "\n",
            "Now remove the node with the given key from the linked list.\n",
            "```cpp\n",
            "struct Node {\n",
            "    int data;\n",
            "    struct Node *next;\n",
            "};\n",
            "void deleteNode(struct Node **head, int key) {\n",
            "    // TODO : Implement node deletion\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step-by-step, walk through identifying the target node and safely unlinking it.\n",
            "```cpp\n",
            "struct Node {\n",
            "    int data;\n",
            "    struct Node *next;\n",
            "};\n",
            "void deleteNode(struct Node **head, int key) {\n",
            "    // TODO : Implement node deletion\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Complete the recursive Fibonacci function to return the nth number.\n",
            "```python\n",
            "def fibonacci(n):\n",
            "    # TODO : Base cases and recursive call\n",
            "    pass\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Example:\n",
            "Input: fibonacci(0) â†’ 0\n",
            "Input: fibonacci(1) â†’ 1\n",
            "Output: fibonacci(5) â†’ 5\n",
            "\n",
            "Now implement the recursive function:\n",
            "```python\n",
            "def fibonacci(n):\n",
            "    # TODO : Base cases and recursive call\n",
            "    pass\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Write a constructor that initializes `name`, `age`, and optional `email` fields.\n",
            "```python\n",
            "class Person:\n",
            "    def __init__(self):\n",
            "        # TODO : Add name , age , and optional email\n",
            "        pass\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Identify which attributes should be stored.\n",
            "Step 2: Use parameters in `__init__` to initialize them.\n",
            "```python\n",
            "class Person:\n",
            "    def __init__(self):\n",
            "        # TODO : Add name , age , and optional email\n",
            "        pass\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Example:\n",
            "Input: binarySearch([1, 3, 5, 7], 5) â†’ 2\n",
            "Now implement binary search to find the target in the array.\n",
            "```java\n",
            "public int binarySearch(int[] arr, int target) {\n",
            "    int left = 0, right = arr.length - 1;\n",
            "    while (left <= right) {\n",
            "        int mid = (left + right) / 2;\n",
            "        // TODO : Compare and adjust bounds\n",
            "    }\n",
            "    return -1;\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step-by-step, adjust the left/right bounds depending on how mid compares to the target.\n",
            "```java\n",
            "public int binarySearch(int[] arr, int target) {\n",
            "    int left = 0, right = arr.length - 1;\n",
            "    while (left <= right) {\n",
            "        int mid = (left + right) / 2;\n",
            "        // TODO : Compare and adjust bounds\n",
            "    }\n",
            "    return -1;\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " The function is named isOdd but returns true for even numbers. Fix the logic or rename the function to match its behavior.\n",
            "```cpp\n",
            "bool isOdd(int x) {\n",
            "    return x % 2 == 0;\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step-by-step, identify the contradiction between the functionâ€™s intent and logic, then revise accordingly.\n",
            "```cpp\n",
            "bool isOdd(int x) {\n",
            "    return x % 2 == 0;\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Fix the function so it returns a Boolean value when checking for even numbers.\n",
            "```cpp\n",
            "function isEven(n) {\n",
            "    return n % 2; // Returns 1 or 0 , not true / false\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Identify what `n % 2` returns.\n",
            "Step 2: Modify the function so the result is explicitly a Boolean.\n",
            "```cpp\n",
            "function isEven(n) {\n",
            "    return n % 2; // Returns 1 or 0 , not true / false\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step-by-step, explain what the function checks and how it transforms the input.\n",
            "```cpp\n",
            "int process(int x) {\n",
            "    if (x < 0) return -1;\n",
            "    return x * x;\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Validate input.\n",
            "Step 2: Describe the square operation and why it's used.\n",
            "```cpp\n",
            "int process(int x) {\n",
            "    if (x < 0) return -1;\n",
            "    return x * x;\n",
            "}\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Example:\n",
            "Input: [90, 80, 70] â†’ Output: 80.0\n",
            "Now complete the function to return the average score.\n",
            "```python\n",
            "def calculate_average(scores):\n",
            "    total = 0\n",
            "    # TODO : Complete to return average\n",
            "    pass\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step-by-step, explain how to sum the elements and divide by the count for the average.\n",
            "```python\n",
            "def calculate_average(scores):\n",
            "    total = 0\n",
            "    # TODO : Complete to return average\n",
            "    pass\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Read the CSV file safely.\n",
            "Step 2: Summarize the column.\n",
            "Step 3: Identify areas to improve structure or error handling.\n",
            "```python\n",
            "# utils.py\n",
            "import csv\n",
            "\n",
            "def read_csv(filepath):\n",
            "    with open(filepath, 'r') as f:\n",
            "        return [row for row in csv.reader(f)]\n",
            "\n",
            "def summarize_column(data, index):\n",
            "    values = [float(row[index]) for row in data[1:]]\n",
            "    total = sum(values)\n",
            "    avg = total / len(values)\n",
            "    return total, avg\n",
            "\n",
            "def main():\n",
            "    filepath = 'data.csv'\n",
            "    data = read_csv(filepath)\n",
            "    total, avg = summarize_column(data, 1)\n",
            "    print(\"Total:\", total)\n",
            "    print(\"Average:\", avg)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Ensure the logic is robust when parsing input and summarizing data. Refactor to avoid assumptions like non-empty input.\n",
            "```python\n",
            "# utils.py\n",
            "import csv\n",
            "\n",
            "def read_csv(filepath):\n",
            "    with open(filepath, 'r') as f:\n",
            "        return [row for row in csv.reader(f)]\n",
            "\n",
            "def summarize_column(data, index):\n",
            "    values = [float(row[index]) for row in data[1:]]\n",
            "    total = sum(values)\n",
            "    avg = total / len(values)\n",
            "    return total, avg\n",
            "\n",
            "def main():\n",
            "    filepath = 'data.csv'\n",
            "    data = read_csv(filepath)\n",
            "    total, avg = summarize_column(data, 1)\n",
            "    print(\"Total:\", total)\n",
            "    print(\"Average:\", avg)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Complete the missing cleaning logic and make sure word frequencies are calculated correctly.\n",
            "```python\n",
            "# file_processor.py\n",
            "import string\n",
            "\n",
            "def load_file(filepath):\n",
            "    with open(filepath, 'r') as f:\n",
            "        return f.readlines()\n",
            "\n",
            "def clean_line(line):\n",
            "    # TODO : Remove punctuation and make lowercase\n",
            "    pass\n",
            "\n",
            "def count_words(lines):\n",
            "    word_counts = {}\n",
            "    for line in lines:\n",
            "        clean = clean_line(line)\n",
            "        for word in clean.split():\n",
            "            word_counts[word] = word_counts.get(word, 0) + 1\n",
            "    return word_counts\n",
            "\n",
            "def main():\n",
            "    filepath = 'input.txt'\n",
            "    lines = load_file(filepath)\n",
            "    counts = count_words(lines)\n",
            "    for word, count in sorted(counts.items()):\n",
            "        print(f\"{word}: {count}\")\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "```\n",
            "ğŸ“ PROMPT:\n",
            " Step 1: Describe how to normalize and clean a line of text.\n",
            "Step 2: Integrate the cleaned lines into the word counting logic.\n",
            "```python\n",
            "# file_processor.py\n",
            "import string\n",
            "\n",
            "def load_file(filepath):\n",
            "    with open(filepath, 'r') as f:\n",
            "        return f.readlines()\n",
            "\n",
            "def clean_line(line):\n",
            "    # TODO : Remove punctuation and make lowercase\n",
            "    pass\n",
            "\n",
            "def count_words(lines):\n",
            "    word_counts = {}\n",
            "    for line in lines:\n",
            "        clean = clean_line(line)\n",
            "        for word in clean.split():\n",
            "            word_counts[word] = word_counts.get(word, 0) + 1\n",
            "    return word_counts\n",
            "\n",
            "def main():\n",
            "    filepath = 'input.txt'\n",
            "    lines = load_file(filepath)\n",
            "    counts = count_words(lines)\n",
            "    for word, count in sorted(counts.items()):\n",
            "        print(f\"{word}: {count}\")\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    main()\n",
            "```\n",
            "ğŸ” Total jobs to run: 88\n",
            "â†’ Starting: task01_code_summarization | zero_shot @ ChatGPT\n",
            "â†’ Starting: task01_code_summarization | zero_shot @ Codestral\n",
            "â†’ Starting: task01_code_summarization | few_shot @ ChatGPT\n",
            "â†’ Starting: task01_code_summarization | few_shot @ Codestral\n",
            "âœ“ Completed: task01_code_summarization | few_shot @ Codestral\n",
            "â†’ Starting: task02_bug_fixing_off_by_one | few_shot @ ChatGPT\n",
            "âœ“ Completed: task01_code_summarization | few_shot @ ChatGPT\n",
            "â†’ Starting: task02_bug_fixing_off_by_one | few_shot @ Codestral\n",
            "âœ“ Completed: task02_bug_fixing_off_by_one | few_shot @ Codestral\n",
            "â†’ Starting: task02_bug_fixing_off_by_one | chain_of_thought @ ChatGPT\n",
            "âœ“ Completed: task01_code_summarization | zero_shot @ Codestral\n",
            "â†’ Starting: task02_bug_fixing_off_by_one | chain_of_thought @ Codestral\n",
            "âœ“ Completed: task01_code_summarization | zero_shot @ ChatGPT\n",
            "â†’ Starting: task03_bug_classification_cpp | chain_of_thought @ ChatGPT\n",
            "âœ“ Completed: task02_bug_fixing_off_by_one | few_shot @ ChatGPT\n",
            "â†’ Starting: task03_bug_classification_cpp | chain_of_thought @ Codestral\n",
            "âœ“ Completed: task03_bug_classification_cpp | chain_of_thought @ ChatGPT\n",
            "â†’ Starting: task03_bug_classification_cpp | prompt_chaining @ ChatGPT\n",
            "âœ“ Completed: task02_bug_fixing_off_by_one | chain_of_thought @ Codestral\n",
            "â†’ Starting: task03_bug_classification_cpp | prompt_chaining @ Codestral\n",
            "âœ“ Completed: task02_bug_fixing_off_by_one | chain_of_thought @ ChatGPT\n",
            "â†’ Starting: task04_email_validator | prompt_chaining @ ChatGPT\n",
            "âœ“ Completed: task03_bug_classification_cpp | chain_of_thought @ Codestral\n",
            "â†’ Starting: task04_email_validator | prompt_chaining @ Codestral\n",
            "âœ“ Completed: task04_email_validator | prompt_chaining @ ChatGPT\n",
            "â†’ Starting: task04_email_validator | chain_of_thought @ ChatGPT\n",
            "âœ“ Completed: task03_bug_classification_cpp | prompt_chaining @ Codestral\n",
            "â†’ Starting: task04_email_validator | chain_of_thought @ Codestral\n",
            "âœ“ Completed: task04_email_validator | prompt_chaining @ Codestral\n",
            "â†’ Starting: task05_flask_api | zero_shot @ ChatGPT\n",
            "âœ“ Completed: task04_email_validator | chain_of_thought @ ChatGPT\n",
            "â†’ Starting: task05_flask_api | zero_shot @ Codestral\n",
            "âœ“ Completed: task03_bug_classification_cpp | prompt_chaining @ ChatGPT\n",
            "â†’ Starting: task05_flask_api | self_consistency @ ChatGPT\n",
            "  â€¢ SC run 1/3 for model 'gpt-4o-mini'...\n",
            "âœ“ Completed: task05_flask_api | zero_shot @ ChatGPT\n",
            "â†’ Starting: task05_flask_api | self_consistency @ Codestral\n",
            "  â€¢ SC run 1/3 for model 'Codestral-2501'...\n",
            "âœ“ Completed: task04_email_validator | chain_of_thought @ Codestral\n",
            "â†’ Starting: task06_sql_schema | zero_shot @ ChatGPT\n",
            "âœ“ Completed: task05_flask_api | zero_shot @ Codestral\n",
            "â†’ Starting: task06_sql_schema | zero_shot @ Codestral\n",
            "  â€¢ SC run 2/3 for model 'Codestral-2501'...\n",
            "  â€¢ SC run 2/3 for model 'gpt-4o-mini'...\n",
            "  â€¢ SC run 3/3 for model 'Codestral-2501'...\n",
            "  â€¢ SC run 3/3 for model 'gpt-4o-mini'...\n",
            "âœ“ Completed: task06_sql_schema | zero_shot @ Codestral\n",
            "â†’ Starting: task06_sql_schema | self_consistency @ ChatGPT\n",
            "  â€¢ SC run 1/3 for model 'gpt-4o-mini'...\n",
            "âœ“ Completed: task06_sql_schema | zero_shot @ ChatGPT\n",
            "â†’ Starting: task06_sql_schema | self_consistency @ Codestral\n",
            "  â€¢ SC run 1/3 for model 'Codestral-2501'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f90b64b0b4a41799726f4a280bbbf53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  â€¢ SC run 2/3 for model 'Codestral-2501'...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "679b8022a0744af5af1f1162dcf7c18b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Completed: task05_flask_api | self_consistency @ Codestral\n",
            "â†’ Starting: task07_null_deref_java | few_shot @ ChatGPT\n",
            "âœ“ Completed: task05_flask_api | self_consistency @ ChatGPT\n",
            "â†’ Starting: task07_null_deref_java | few_shot @ Codestral\n",
            "âœ“ Completed: task07_null_deref_java | few_shot @ ChatGPT\n",
            "â†’ Starting: task07_null_deref_java | chain_of_thought @ ChatGPT\n",
            "  â€¢ SC run 2/3 for model 'gpt-4o-mini'...\n",
            "âœ“ Completed: task07_null_deref_java | few_shot @ Codestral\n",
            "â†’ Starting: task07_null_deref_java | chain_of_thought @ Codestral\n",
            "  â€¢ SC run 3/3 for model 'Codestral-2501'...\n",
            "  â€¢ SC run 3/3 for model 'gpt-4o-mini'...\n",
            "âœ“ Completed: task07_null_deref_java | chain_of_thought @ Codestral\n",
            "â†’ Starting: task08_csv_parser | few_shot @ ChatGPT\n",
            "âœ“ Completed: task07_null_deref_java | chain_of_thought @ ChatGPT\n",
            "â†’ Starting: task08_csv_parser | few_shot @ Codestral\n",
            "âœ“ Completed: task08_csv_parser | few_shot @ Codestral\n",
            "â†’ Starting: task08_csv_parser | chain_of_thought @ ChatGPT\n",
            "âœ“ Completed: task06_sql_schema | self_consistency @ Codestral\n",
            "â†’ Starting: task08_csv_parser | chain_of_thought @ Codestral\n",
            "âœ“ Completed: task08_csv_parser | few_shot @ ChatGPT\n",
            "â†’ Starting: task09_kotlin_api | prompt_chaining @ ChatGPT\n",
            "âœ“ Completed: task06_sql_schema | self_consistency @ ChatGPT\n",
            "â†’ Starting: task09_kotlin_api | prompt_chaining @ Codestral\n",
            "âœ“ Completed: task08_csv_parser | chain_of_thought @ Codestral\n",
            "â†’ Starting: task09_kotlin_api | self_consistency @ ChatGPT\n",
            "  â€¢ SC run 1/3 for model 'gpt-4o-mini'...\n",
            "âœ“ Completed: task08_csv_parser | chain_of_thought @ ChatGPT\n",
            "â†’ Starting: task09_kotlin_api | self_consistency @ Codestral\n",
            "  â€¢ SC run 1/3 for model 'Codestral-2501'...\n",
            "âœ“ Completed: task09_kotlin_api | prompt_chaining @ ChatGPT\n",
            "â†’ Starting: task10_func_summary_py | prompt_chaining @ ChatGPT\n",
            "âœ“ Completed: task10_func_summary_py | prompt_chaining @ ChatGPT\n",
            "â†’ Starting: task10_func_summary_py | prompt_chaining @ Codestral\n",
            "âœ“ Completed: task10_func_summary_py | prompt_chaining @ Codestral\n",
            "â†’ Starting: task10_func_summary_py | self_consistency @ ChatGPT\n",
            "  â€¢ SC run 1/3 for model 'gpt-4o-mini'...\n",
            "  â€¢ SC run 2/3 for model 'gpt-4o-mini'...\n",
            "âœ“ Completed: task09_kotlin_api | prompt_chaining @ Codestral\n",
            "â†’ Starting: task10_func_summary_py | self_consistency @ Codestral\n",
            "  â€¢ SC run 1/3 for model 'Codestral-2501'...\n",
            "  â€¢ SC run 3/3 for model 'gpt-4o-mini'...\n",
            "  â€¢ SC run 2/3 for model 'gpt-4o-mini'...\n",
            "  â€¢ SC run 2/3 for model 'Codestral-2501'...\n",
            "  â€¢ SC run 2/3 for model 'Codestral-2501'...\n",
            "  â€¢ SC run 3/3 for model 'Codestral-2501'...\n",
            "âœ“ Completed: task10_func_summary_py | self_consistency @ ChatGPT\n",
            "â†’ Starting: task11_prompt_from_comments | chain_of_thought @ ChatGPT\n",
            "âœ“ Completed: task10_func_summary_py | self_consistency @ Codestral\n",
            "â†’ Starting: task11_prompt_from_comments | chain_of_thought @ Codestral\n",
            "  â€¢ SC run 3/3 for model 'gpt-4o-mini'...\n",
            "  â€¢ SC run 3/3 for model 'Codestral-2501'...\n",
            "âœ“ Completed: task11_prompt_from_comments | chain_of_thought @ ChatGPT\n",
            "â†’ Starting: task11_prompt_from_comments | prompt_chaining @ ChatGPT\n",
            "âœ“ Completed: task11_prompt_from_comments | chain_of_thought @ Codestral\n",
            "â†’ Starting: task11_prompt_from_comments | prompt_chaining @ Codestral\n",
            "âœ“ Completed: task11_prompt_from_comments | prompt_chaining @ ChatGPT\n",
            "â†’ Starting: task12_fix_factorial_bug | self-consistency @ ChatGPT\n",
            "âœ“ Completed: task11_prompt_from_comments | prompt_chaining @ Codestral\n",
            "â†’ Starting: task12_fix_factorial_bug | self-consistency @ Codestral\n",
            "âœ“ Completed: task12_fix_factorial_bug | self-consistency @ Codestral\n",
            "â†’ Starting: task12_fix_factorial_bug | chain-of-thought @ ChatGPT\n",
            "âœ“ Completed: task12_fix_factorial_bug | self-consistency @ ChatGPT\n",
            "â†’ Starting: task12_fix_factorial_bug | chain-of-thought @ Codestral\n",
            "âœ“ Completed: task09_kotlin_api | self_consistency @ ChatGPT\n",
            "â†’ Starting: task13_delete_linked_list_node | few-shot @ ChatGPT\n",
            "âœ“ Completed: task09_kotlin_api | self_consistency @ Codestral\n",
            "â†’ Starting: task13_delete_linked_list_node | few-shot @ Codestral\n",
            "âœ“ Completed: task12_fix_factorial_bug | chain-of-thought @ ChatGPT\n",
            "â†’ Starting: task13_delete_linked_list_node | chain-of-thought @ ChatGPT\n",
            "âœ“ Completed: task12_fix_factorial_bug | chain-of-thought @ Codestral\n",
            "â†’ Starting: task13_delete_linked_list_node | chain-of-thought @ Codestral\n",
            "âœ“ Completed: task13_delete_linked_list_node | chain-of-thought @ ChatGPT\n",
            "â†’ Starting: task14_recursive_fibonacci | zero-shot @ ChatGPT\n",
            "âœ“ Completed: task13_delete_linked_list_node | few-shot @ Codestral\n",
            "â†’ Starting: task14_recursive_fibonacci | zero-shot @ Codestral\n",
            "âœ“ Completed: task14_recursive_fibonacci | zero-shot @ Codestral\n",
            "â†’ Starting: task14_recursive_fibonacci | few-shot @ ChatGPT\n",
            "âœ“ Completed: task14_recursive_fibonacci | zero-shot @ ChatGPT\n",
            "â†’ Starting: task14_recursive_fibonacci | few-shot @ Codestral\n",
            "âœ“ Completed: task13_delete_linked_list_node | few-shot @ ChatGPT\n",
            "â†’ Starting: task15_constructor_completion | zero-shot @ ChatGPT\n",
            "âœ“ Completed: task14_recursive_fibonacci | few-shot @ ChatGPT\n",
            "â†’ Starting: task15_constructor_completion | zero-shot @ Codestral\n",
            "âœ“ Completed: task14_recursive_fibonacci | few-shot @ Codestral\n",
            "â†’ Starting: task15_constructor_completion | prompt chaining @ ChatGPT\n",
            "âœ“ Completed: task13_delete_linked_list_node | chain-of-thought @ Codestral\n",
            "â†’ Starting: task15_constructor_completion | prompt chaining @ Codestral\n",
            "âœ“ Completed: task15_constructor_completion | zero-shot @ ChatGPT\n",
            "â†’ Starting: task16_binary_search_java | few-shot @ ChatGPT\n",
            "âœ“ Completed: task15_constructor_completion | prompt chaining @ Codestral\n",
            "â†’ Starting: task16_binary_search_java | few-shot @ Codestral\n",
            "âœ“ Completed: task15_constructor_completion | prompt chaining @ ChatGPT\n",
            "â†’ Starting: task16_binary_search_java | chain-of-thought @ ChatGPT\n",
            "âœ“ Completed: task15_constructor_completion | zero-shot @ Codestral\n",
            "â†’ Starting: task16_binary_search_java | chain-of-thought @ Codestral\n",
            "âœ“ Completed: task16_binary_search_java | few-shot @ ChatGPT\n",
            "â†’ Starting: task17_fix_even_logic | self-consistency @ ChatGPT\n",
            "âœ“ Completed: task16_binary_search_java | few-shot @ Codestral\n",
            "â†’ Starting: task17_fix_even_logic | self-consistency @ Codestral\n",
            "âœ“ Completed: task16_binary_search_java | chain-of-thought @ Codestral\n",
            "â†’ Starting: task17_fix_even_logic | chain-of-thought @ ChatGPT\n",
            "âœ“ Completed: task16_binary_search_java | chain-of-thought @ ChatGPT\n",
            "â†’ Starting: task17_fix_even_logic | chain-of-thought @ Codestral\n",
            "âœ“ Completed: task17_fix_even_logic | self-consistency @ ChatGPT\n",
            "â†’ Starting: task18_fix_js_is_even | zero-shot @ ChatGPT\n",
            "âœ“ Completed: task17_fix_even_logic | self-consistency @ Codestral\n",
            "â†’ Starting: task18_fix_js_is_even | zero-shot @ Codestral\n",
            "âœ“ Completed: task18_fix_js_is_even | zero-shot @ ChatGPT\n",
            "â†’ Starting: task18_fix_js_is_even | prompt chaining @ ChatGPT\n",
            "âœ“ Completed: task17_fix_even_logic | chain-of-thought @ ChatGPT\n",
            "â†’ Starting: task18_fix_js_is_even | prompt chaining @ Codestral\n",
            "âœ“ Completed: task18_fix_js_is_even | zero-shot @ Codestral\n",
            "â†’ Starting: task19_decompose_summary_cpp | chain-of-thought @ ChatGPT\n",
            "âœ“ Completed: task17_fix_even_logic | chain-of-thought @ Codestral\n",
            "â†’ Starting: task19_decompose_summary_cpp | chain-of-thought @ Codestral\n",
            "âœ“ Completed: task18_fix_js_is_even | prompt chaining @ ChatGPT\n",
            "â†’ Starting: task19_decompose_summary_cpp | prompt chaining @ ChatGPT\n",
            "âœ“ Completed: task18_fix_js_is_even | prompt chaining @ Codestral\n",
            "â†’ Starting: task19_decompose_summary_cpp | prompt chaining @ Codestral\n",
            "âœ“ Completed: task19_decompose_summary_cpp | chain-of-thought @ Codestral\n",
            "â†’ Starting: task20_calculate_average | few-shot @ ChatGPT\n",
            "âœ“ Completed: task19_decompose_summary_cpp | chain-of-thought @ ChatGPT\n",
            "â†’ Starting: task20_calculate_average | few-shot @ Codestral\n",
            "âœ“ Completed: task19_decompose_summary_cpp | prompt chaining @ ChatGPT\n",
            "â†’ Starting: task20_calculate_average | chain-of-thought @ ChatGPT\n",
            "âœ“ Completed: task19_decompose_summary_cpp | prompt chaining @ Codestral\n",
            "â†’ Starting: task20_calculate_average | chain-of-thought @ Codestral\n",
            "âœ“ Completed: task20_calculate_average | few-shot @ ChatGPT\n",
            "â†’ Starting: task21_refactor_utils | prompt chaining @ ChatGPT\n",
            "âœ“ Completed: task20_calculate_average | few-shot @ Codestral\n",
            "â†’ Starting: task21_refactor_utils | prompt chaining @ Codestral\n",
            "âœ“ Completed: task20_calculate_average | chain-of-thought @ ChatGPT\n",
            "â†’ Starting: task21_refactor_utils | self-consistency @ ChatGPT\n",
            "âœ“ Completed: task20_calculate_average | chain-of-thought @ Codestral\n",
            "â†’ Starting: task21_refactor_utils | self-consistency @ Codestral\n",
            "âœ“ Completed: task21_refactor_utils | self-consistency @ Codestral\n",
            "â†’ Starting: task22_complete_file_processor | zero-shot @ ChatGPT\n",
            "âœ“ Completed: task21_refactor_utils | prompt chaining @ Codestral\n",
            "â†’ Starting: task22_complete_file_processor | zero-shot @ Codestral\n",
            "âœ“ Completed: task21_refactor_utils | self-consistency @ ChatGPT\n",
            "â†’ Starting: task22_complete_file_processor | prompt chaining @ ChatGPT\n",
            "âœ“ Completed: task21_refactor_utils | prompt chaining @ ChatGPT\n",
            "â†’ Starting: task22_complete_file_processor | prompt chaining @ Codestral\n",
            "âœ“ Completed: task22_complete_file_processor | zero-shot @ ChatGPT\n",
            "âœ“ Completed: task22_complete_file_processor | zero-shot @ Codestral\n",
            "âœ“ Completed: task22_complete_file_processor | prompt chaining @ ChatGPT\n",
            "âœ“ Completed: task22_complete_file_processor | prompt chaining @ Codestral\n",
            "âœ… All outputs have been generated and saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import evaluate\n",
        "\n",
        "# Set environment variable for API key (example, remove in production)\n",
        "# Create your PAT token by following instructions here:\n",
        "# https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
        "# grab the token from the token.txt file\n",
        "with open(\"token.txt\", \"r\") as f:\n",
        "  GITHUB_TOKEN = f.read().strip()\n",
        "\n",
        "\n",
        "# Initialize the OpenAI client (replace base_url if needed)\n",
        "client = OpenAI(\n",
        "    base_url=\"https://models.inference.ai.azure.com\",\n",
        "    api_key=api_key=GITHUB_TOKEN\n",
        ")\n",
        "\n",
        "# Define models\n",
        "MODEL_CONFIG = [\n",
        "    (\"gpt-4o-mini\", \"ChatGPT\"),\n",
        "    (\"Codestral-2501\", \"Codestral\"),\n",
        "]\n",
        "\n",
        "model_choices, model_names = zip(*MODEL_CONFIG)\n",
        "\n",
        "# Updated EXAMPLES dictionary with all 22 tasks in chronological order\n",
        "EXAMPLES = {\n",
        "    \"task01_code_summarization\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"public Map<String, Integer> countWordFrequency(List<String> words) {\n",
        "    Map<String, Integer> freqMap = new HashMap<>();\n",
        "    for (String word : words) {\n",
        "        freqMap.put(word, freqMap.getOrDefault(word, 0) + 1);\n",
        "    }\n",
        "    return freqMap;\n",
        "}\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Summarize the functionality of the following Java method:\",\n",
        "            \"few_shot\": \"Example:\\nInput: a Java method that counts the frequency of each character in a string.\\nOutput: This method takes a string as input and returns a map where each key is a character from the string, and the value is the number of times that character appears.\\n\\nNow, summarize the functionality of the following Java method:\"\n",
        "        }\n",
        "    },\n",
        "    \"task02_bug_fixing_off_by_one\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def sum_range(start, end):\n",
        "    total = 0\n",
        "    for i in range(start, end):\n",
        "        total += i\n",
        "    return total\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"few_shot\": \"Example:\\nInput: start=1, end=4 â†’ Output: 6 (This sums 1+2+3)\\nNow identify and fix the off-by-one error in the following function:\",\n",
        "            \"chain_of_thought\": \"Think step-by-step to find and correct the off-by-one error in the following Python function:\"\n",
        "        }\n",
        "    },\n",
        "    \"task03_bug_classification_cpp\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"int * getArray(int size) {\n",
        "    int arr[size]; // Warning: local array\n",
        "    return arr;    // Bug: returning pointer to local variable\n",
        "}\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"chain_of_thought\": \"Walk through your reasoning step-by-step and classify the bug in the following C++ function:\",\n",
        "            \"prompt_chaining\": \"Step 1: Identify the bug in the following C++ function.\\nStep 2: Explain why it occurs and its consequences.\"\n",
        "        }\n",
        "    },\n",
        "    \"task04_email_validator\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def is_valid_email(email):\n",
        "    # TODO: Complete using regex\n",
        "    pass\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"prompt_chaining\": \"Step 1: Provide a regex pattern for basic email addresses (e.g., user@domain.com).\\nStep 2: Implement `is_valid_email` using that pattern in the following code:\",\n",
        "            \"chain_of_thought\": \"Think step-by-step to derive a regex and implement `is_valid_email` in the following code:\"\n",
        "        }\n",
        "    },\n",
        "    \"task05_flask_api\": {\n",
        "        \"type\": \"generation\",\n",
        "        \"expected\": \"\"\"from flask import Flask, jsonify\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/greet/<username>')\n",
        "def greet(username):\n",
        "    return jsonify({'greeting': f'Hello, {username}!'})\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Create a Flask `/greet/<username>` endpoint that returns a JSON greeting.\",\n",
        "            \"self_consistency\": \"Create a Flask `/greet/<username>` endpoint that returns a JSON greeting.\"\n",
        "        }\n",
        "    },\n",
        "    \"task06_sql_schema\": {\n",
        "        \"type\": \"generation\",\n",
        "        \"expected\": \"\"\"-- users(id INT PRIMARY KEY, name VARCHAR(100));\n",
        "-- books(id INT PRIMARY KEY, title VARCHAR(200));\n",
        "-- reviews(id INT PRIMARY KEY, user_id INT REFERENCES users(id), book_id INT REFERENCES books(id), rating INT);\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"zero_shot\": \"Write SQL schema (tables, primary & foreign keys) for a review app with users, books, and reviews. -- TODO : Design schema with appropriate keys and constraints -- Tables : users (id , name ), books (id , title ), reviews (id , user_id , book_id , rating )\",\n",
        "            \"self_consistency\": \"Write SQL schema (tables, primary & foreign keys) for a review app with users, books, and reviews. -- TODO : Design schema with appropriate keys and constraints -- Tables : users (id , name ), books (id , title ), reviews (id , user_id , book_id , rating )\"\n",
        "        }\n",
        "    },\n",
        "    \"task07_null_deref_java\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"public int getLength(String s) {\n",
        "    return s.length(); // What if s is null?\n",
        "}\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"few_shot\": \"Example:\\nInput: a method with a null check before length().\\nOutput: Checks if the string is null before calling length to avoid null-dereference.\\nNow identify null-dereference risk in the following code:\",\n",
        "            \"chain_of_thought\": \"Reason step-by-step to find any null-dereference risk in the following Java code:\"\n",
        "        }\n",
        "    },\n",
        "    \"task08_csv_parser\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def parse_csv_line(line):\n",
        "    return line.split(',')  # Incomplete: doesn't handle quoted fields\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"few_shot\": \"Example:\\nInput: '\\\"a,b\\\",c' â†’ Output: ['a,b','c']\\nNow improve the following CSV parser:\",\n",
        "            \"chain_of_thought\": \"Think step-by-step to split CSV fields correctly, handling quotes, in the following code:\"\n",
        "        }\n",
        "    },\n",
        "    \"task09_kotlin_api\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"data class Product(val id: Int, val name: String, val price: Double)\n",
        "// TODO: Create GET and POST endpoints using Ktor\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"prompt_chaining\": \"Step 1: Define GET `/product/{id}` returning JSON.\\nStep 2: Define POST endpoint accepting a Product in the body for the following code:\",\n",
        "            \"self_consistency\": \"Convert the following Kotlin data class to a REST API with GET and POST endpoints using Ktor.\"\n",
        "        }\n",
        "    },\n",
        "    \"task10_func_summary_py\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"def reverse_words(sentence):\n",
        "    return ' '.join(sentence.split()[::-1])\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"prompt_chaining\": \"Step 1: Describe what the following function does.\\nStep 2: Summarize it in one sentence:\",\n",
        "            \"self_consistency\": \"Write a brief summary of the following function.\"\n",
        "        }\n",
        "    },\n",
        "    \"task11_prompt_from_comments\": {\n",
        "        \"type\": \"analysis\",\n",
        "        \"snippet\": \"\"\"# This function checks if a number is prime\n",
        "def is_prime(n):\n",
        "    if n <= 1: return False\n",
        "    for i in range(2, int(n**0.5)+1):\n",
        "        if n % i == 0: return False\n",
        "    return True\n",
        "\"\"\",\n",
        "        \"strategies\": {\n",
        "            \"chain_of_thought\": \"Explain step-by-step how to craft a prompt to generate the following code:\",\n",
        "            \"prompt_chaining\": \"Step 1: Write a system instruction that sets the task.\\nStep 2: Provide the comment and ask for implementation for the following code:\"\n",
        "        }\n",
        "    },\n",
        "    \"task12_fix_factorial_bug\": {\n",
        "    \"type\": \"bug_fixing\",\n",
        "    \"snippet\": \"def factorial(n):\\n    result = 1\\n    for i in range(1, n):\\n        result *= i\\n    return result\",\n",
        "    \"strategies\": {\n",
        "        \"self-consistency\": \"The logic fails for n = 0 due to incorrect loop bounds. Revise it so the function returns 1 for 0 and behaves consistently for all inputs.\",\n",
        "        \"chain-of-thought\": \"Step-by-step, identify how the loop behaves for n = 0 and adjust it to include the base case explicitly.\"\n",
        "    }\n",
        "},\n",
        "\"task13_delete_linked_list_node\": {\n",
        "    \"type\": \"data_structure\",\n",
        "    \"snippet\": \"struct Node {\\n    int data;\\n    struct Node *next;\\n};\\nvoid deleteNode(struct Node **head, int key) {\\n    // TODO : Implement node deletion\\n}\",\n",
        "    \"strategies\": {\n",
        "        \"few-shot\": \"Example:\\nInput: struct Node *head; int key = 4;\\nOutput: Node with value 4 is removed from the list.\\n\\nNow remove the node with the given key from the linked list.\",\n",
        "        \"chain-of-thought\": \"Step-by-step, walk through identifying the target node and safely unlinking it.\"\n",
        "    }\n",
        "},\n",
        "\"task14_recursive_fibonacci\": {\n",
        "    \"type\": \"function_completion\",\n",
        "    \"snippet\": \"def fibonacci(n):\\n    # TODO : Base cases and recursive call\\n    pass\",\n",
        "    \"strategies\": {\n",
        "        \"zero-shot\": \"Complete the recursive Fibonacci function to return the nth number.\",\n",
        "        \"few-shot\": \"Example:\\nInput: fibonacci(0) â†’ 0\\nInput: fibonacci(1) â†’ 1\\nOutput: fibonacci(5) â†’ 5\\n\\nNow implement the recursive function:\"\n",
        "    }\n",
        "},\n",
        "\"task15_constructor_completion\": {\n",
        "    \"type\": \"class_definition\",\n",
        "    \"snippet\": \"class Person:\\n    def __init__(self):\\n        # TODO : Add name , age , and optional email\\n        pass\",\n",
        "    \"strategies\": {\n",
        "        \"zero-shot\": \"Write a constructor that initializes `name`, `age`, and optional `email` fields.\",\n",
        "        \"prompt chaining\": \"Step 1: Identify which attributes should be stored.\\nStep 2: Use parameters in `__init__` to initialize them.\"\n",
        "    }\n",
        "},\n",
        "\"task16_binary_search_java\": {\n",
        "    \"type\": \"algorithm_completion\",\n",
        "    \"snippet\": \"public int binarySearch(int[] arr, int target) {\\n    int left = 0, right = arr.length - 1;\\n    while (left <= right) {\\n        int mid = (left + right) / 2;\\n        // TODO : Compare and adjust bounds\\n    }\\n    return -1;\\n}\",\n",
        "    \"strategies\": {\n",
        "        \"few-shot\": \"Example:\\nInput: binarySearch([1, 3, 5, 7], 5) â†’ 2\\nNow implement binary search to find the target in the array.\",\n",
        "        \"chain-of-thought\": \"Step-by-step, adjust the left/right bounds depending on how mid compares to the target.\"\n",
        "    }\n",
        "},\n",
        "\"task17_fix_even_logic\": {\n",
        "    \"type\": \"self_consistency\",\n",
        "    \"snippet\": \"bool isOdd(int x) {\\n    return x % 2 == 0;\\n}\",\n",
        "    \"strategies\": {\n",
        "        \"self-consistency\": \"The function is named isOdd but returns true for even numbers. Fix the logic or rename the function to match its behavior.\",\n",
        "        \"chain-of-thought\": \"Step-by-step, identify the contradiction between the functionâ€™s intent and logic, then revise accordingly.\"\n",
        "    }\n",
        "},\n",
        "\"task18_fix_js_is_even\": {\n",
        "    \"type\": \"bug_fixing\",\n",
        "    \"snippet\": \"function isEven(n) {\\n    return n % 2; // Returns 1 or 0 , not true / false\\n}\",\n",
        "    \"strategies\": {\n",
        "        \"zero-shot\": \"Fix the function so it returns a Boolean value when checking for even numbers.\",\n",
        "        \"prompt chaining\": \"Step 1: Identify what `n % 2` returns.\\nStep 2: Modify the function so the result is explicitly a Boolean.\"\n",
        "    }\n",
        "},\n",
        "\"task19_decompose_summary_cpp\": {\n",
        "    \"type\": \"code_decomposition\",\n",
        "    \"snippet\": \"int process(int x) {\\n    if (x < 0) return -1;\\n    return x * x;\\n}\",\n",
        "    \"strategies\": {\n",
        "        \"chain-of-thought\": \"Step-by-step, explain what the function checks and how it transforms the input.\",\n",
        "        \"prompt chaining\": \"Step 1: Validate input.\\nStep 2: Describe the square operation and why it's used.\"\n",
        "    }\n",
        "},\n",
        "\"task20_calculate_average\": {\n",
        "    \"type\": \"function_completion\",\n",
        "    \"snippet\": \"def calculate_average(scores):\\n    total = 0\\n    # TODO : Complete to return average\\n    pass\",\n",
        "    \"strategies\": {\n",
        "        \"few-shot\": \"Example:\\nInput: [90, 80, 70] â†’ Output: 80.0\\nNow complete the function to return the average score.\",\n",
        "        \"chain-of-thought\": \"Step-by-step, explain how to sum the elements and divide by the count for the average.\"\n",
        "    }\n",
        "},\n",
        "\"task21_refactor_utils\": {\n",
        "    \"type\": \"refactoring\",\n",
        "    \"snippet\": \"# utils.py\\nimport csv\\n\\ndef read_csv(filepath):\\n    with open(filepath, 'r') as f:\\n        return [row for row in csv.reader(f)]\\n\\ndef summarize_column(data, index):\\n    values = [float(row[index]) for row in data[1:]]\\n    total = sum(values)\\n    avg = total / len(values)\\n    return total, avg\\n\\ndef main():\\n    filepath = 'data.csv'\\n    data = read_csv(filepath)\\n    total, avg = summarize_column(data, 1)\\n    print(\\\"Total:\\\", total)\\n    print(\\\"Average:\\\", avg)\\n\\nif __name__ == '__main__':\\n    main()\",\n",
        "    \"strategies\": {\n",
        "        \"prompt chaining\": \"Step 1: Read the CSV file safely.\\nStep 2: Summarize the column.\\nStep 3: Identify areas to improve structure or error handling.\",\n",
        "        \"self-consistency\": \"Ensure the logic is robust when parsing input and summarizing data. Refactor to avoid assumptions like non-empty input.\"\n",
        "    }\n",
        "},\n",
        "\"task22_complete_file_processor\": {\n",
        "    \"type\": \"function_completion\",\n",
        "    \"snippet\": \"# file_processor.py\\nimport string\\n\\ndef load_file(filepath):\\n    with open(filepath, 'r') as f:\\n        return f.readlines()\\n\\ndef clean_line(line):\\n    # TODO : Remove punctuation and make lowercase\\n    pass\\n\\ndef count_words(lines):\\n    word_counts = {}\\n    for line in lines:\\n        clean = clean_line(line)\\n        for word in clean.split():\\n            word_counts[word] = word_counts.get(word, 0) + 1\\n    return word_counts\\n\\ndef main():\\n    filepath = 'input.txt'\\n    lines = load_file(filepath)\\n    counts = count_words(lines)\\n    for word, count in sorted(counts.items()):\\n        print(f\\\"{word}: {count}\\\")\\n\\nif __name__ == '__main__':\\n    main()\",\n",
        "    \"strategies\": {\n",
        "        \"zero-shot\": \"Complete the missing cleaning logic and make sure word frequencies are calculated correctly.\",\n",
        "        \"prompt chaining\": \"Step 1: Describe how to normalize and clean a line of text.\\nStep 2: Integrate the cleaned lines into the word counting logic.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# Helper to build the prompt based on task type\n",
        "def build_prompt(prefix, snippet=None):\n",
        "    if snippet:\n",
        "        lang = 'java' if 'public' in snippet else 'python' if 'def' in snippet else 'cpp'\n",
        "        prompt = f\"{prefix}\\n```{lang}\\n{snippet}\\n```\"\n",
        "    else:\n",
        "        prompt = f\"{prefix}\\n```{snippet}\\n```\"\n",
        "    print(\"ğŸ“ PROMPT:\\n\", prompt)    # â† right here\n",
        "    return prompt\n",
        "\n",
        "# Safe chat completion with retry\n",
        "def safe_chat_completion(model, prompt, max_retries=3):\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=1024,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return resp.choices[0].message.content.strip()\n",
        "        except Exception as e:\n",
        "            msg = str(e)\n",
        "            m = re.search(r\"wait (\\d+) seconds\", msg)\n",
        "            if m:\n",
        "                wait_secs = int(m.group(1)) + 1\n",
        "                print(f\"ğŸ”’ Rate-limit on '{model}', sleeping {wait_secs}s then retry (attempt {attempt})...\")\n",
        "                time.sleep(wait_secs)\n",
        "                continue\n",
        "            backoff = 2 ** attempt\n",
        "            print(f\"âš ï¸  Error on attempt {attempt} for '{model}': {e}\")\n",
        "            print(f\"  â†’ backing off {backoff}s before retry.\")\n",
        "            time.sleep(backoff)\n",
        "    print(f\"âŒ All retries failed for model '{model}'.\")\n",
        "    return None\n",
        "\n",
        "# Self-consistency runner using BLEU-4 similarity among outputs\n",
        "def run_self_consistency(model, prompt, runs=3):\n",
        "    outputs = []\n",
        "    for i in range(1, runs + 1):\n",
        "        print(f\"  â€¢ SC run {i}/{runs} for model '{model}'...\")\n",
        "        out = safe_chat_completion(model, prompt)\n",
        "        if out:\n",
        "            outputs.append(out)\n",
        "    if not outputs:\n",
        "        return None, []\n",
        "    if len(outputs) == 1:\n",
        "        return outputs[0], outputs\n",
        "\n",
        "    # Load BLEU metric\n",
        "    bleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "    # Compute average BLEU-4 score of each output against others\n",
        "    avg_scores = []\n",
        "    for i, cand in enumerate(outputs):\n",
        "        score_sum = 0.0\n",
        "        count = 0\n",
        "        for j, ref in enumerate(outputs):\n",
        "            if i == j:\n",
        "                continue\n",
        "            result = bleu.compute(predictions=[cand], references=[[ref]])\n",
        "            score_sum += result[\"score\"]\n",
        "            count += 1\n",
        "        avg_scores.append(score_sum / count if count else 0.0)\n",
        "\n",
        "    # Select the output with the highest average BLEU score\n",
        "    best_idx = avg_scores.index(max(avg_scores))\n",
        "    return outputs[best_idx], outputs\n",
        "\n",
        "# Worker executed in parallel\n",
        "def worker(args):\n",
        "    task_key, strat_key, model_id, model_name, prompt = args\n",
        "    print(f\"â†’ Starting: {task_key} | {strat_key} @ {model_name}\")\n",
        "    timestamp = datetime.utcnow().isoformat()\n",
        "    if \"self_consistency\" in strat_key:\n",
        "        output, variants = run_self_consistency(model_id, prompt)\n",
        "    else:\n",
        "        output = safe_chat_completion(model_id, prompt)\n",
        "        variants = []\n",
        "    print(f\"âœ“ Completed: {task_key} | {strat_key} @ {model_name}\")\n",
        "    return {\n",
        "        \"task\": task_key,\n",
        "        \"strategy\": strat_key,\n",
        "        \"model\": model_name,\n",
        "        \"model_id\": model_id,\n",
        "        \"prompt\": prompt,\n",
        "        \"output\": output,\n",
        "        \"variants\": variants,\n",
        "        \"timestamp\": timestamp\n",
        "    }\n",
        "\n",
        "# Orchestrator: builds jobs, runs them, and saves outputs\n",
        "def generate_all():\n",
        "    jobs = []\n",
        "    for task_key, info in EXAMPLES.items():\n",
        "        snippet = info.get(\"snippet\")\n",
        "        for strat_key, prefix in info[\"strategies\"].items():\n",
        "            prompt = build_prompt(prefix, snippet)\n",
        "            for model_id, model_name in MODEL_CONFIG:\n",
        "                jobs.append((task_key, strat_key, model_id, model_name, prompt))\n",
        "    print(f\"ğŸ” Total jobs to run: {len(jobs)}\")\n",
        "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        results = list(executor.map(worker, jobs))\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(\"all_prompts_and_outputs.csv\", index=False)\n",
        "    df.to_json(\"all_prompts_and_outputs.json\", orient=\"records\", indent=2)\n",
        "    print(\"âœ… All outputs have been generated and saved.\")\n",
        "\n",
        "# Run the full pipeline\n",
        "if __name__ == '__main__':\n",
        "    generate_all()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJyGxJDDd-lo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgYPxnh6c5ry"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "156943ba5ed7469da9e98ef6b8b21f24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad62a901af948b4a6a227b0c78c3c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2236967ca8764d8bab1d6ae53adb9bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d38b2a95edf4e6e82d9a936ede02d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2236967ca8764d8bab1d6ae53adb9bb9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c1c14289145244a087ee298cef3ace34",
            "value": "â€‡8.15k/8.15kâ€‡[00:00&lt;00:00,â€‡93.1kB/s]"
          }
        },
        "2d626c92298b4d6e9f2133c60ff32540": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34608d23b28e455a83af745444e1cdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_156943ba5ed7469da9e98ef6b8b21f24",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2d626c92298b4d6e9f2133c60ff32540",
            "value": "â€‡8.15k/8.15kâ€‡[00:00&lt;00:00,â€‡100kB/s]"
          }
        },
        "36b06ada6e574b70a2b02e7fcc8e14de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f45efad3c3145aaaf3098b9141fa4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548f14f5e3884990a9d72807f3732b55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679b8022a0744af5af1f1162dcf7c18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_971f58f582d3426f8fb3e78dbeaf8d2e",
              "IPY_MODEL_cd46b837c5ec44b297376a70f522464c",
              "IPY_MODEL_34608d23b28e455a83af745444e1cdbf"
            ],
            "layout": "IPY_MODEL_548f14f5e3884990a9d72807f3732b55"
          }
        },
        "8c5c32b91aff4fbe96264a63ee708d38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f90b64b0b4a41799726f4a280bbbf53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcf42ad972d543b6bb8a1b05416303eb",
              "IPY_MODEL_f57da60c387244a8803f2ab97e7ce263",
              "IPY_MODEL_2d38b2a95edf4e6e82d9a936ede02d43"
            ],
            "layout": "IPY_MODEL_8c5c32b91aff4fbe96264a63ee708d38"
          }
        },
        "9209616024bd44e788eba940d296f704": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "971f58f582d3426f8fb3e78dbeaf8d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9209616024bd44e788eba940d296f704",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ac3d6c51f66f467aa5cee9a8852639a5",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡100%"
          }
        },
        "ac3d6c51f66f467aa5cee9a8852639a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcf42ad972d543b6bb8a1b05416303eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea270adbb28e414cb8620ced981b1a55",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f695656ee8554f4690f2882389616d76",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡100%"
          }
        },
        "c1c14289145244a087ee298cef3ace34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd46b837c5ec44b297376a70f522464c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36b06ada6e574b70a2b02e7fcc8e14de",
            "max": 8146,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf00bb3a548c4b1783a13ae45b32c856",
            "value": 8146
          }
        },
        "cf00bb3a548c4b1783a13ae45b32c856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea270adbb28e414cb8620ced981b1a55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57da60c387244a8803f2ab97e7ce263": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f45efad3c3145aaaf3098b9141fa4d1",
            "max": 8146,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ad62a901af948b4a6a227b0c78c3c85",
            "value": 8146
          }
        },
        "f695656ee8554f4690f2882389616d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
